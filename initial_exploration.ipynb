{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef646702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "## models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "## to make it possible to display multiple output inside one cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.options.display.max_rows = 50\n",
    "pd.set_option('display.float_format', lambda x: '%9.8f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc41074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression_trials(X_train, y_train):\n",
    "    ## NOTE: this is actually ridge regression, as the default penalty is l2\n",
    "    ## Tries solvers: liblinear and lbfgs\n",
    "\n",
    "    df_list = [] # will be used to create reg_results (full list of scores, one row per run)\n",
    "    reg_mean_scores_df = pd.DataFrame() # mean scores one row per cv run, also has col used to save the models\n",
    "\n",
    "    idx = 0\n",
    "    for cvk in [5,10]:\n",
    "        for solver_name in ['liblinear', 'lbfgs']:\n",
    "            reg_model = LogisticRegression(solver=solver_name)\n",
    "            scores_list = cross_val_score(reg_model, X_train, y_train, cv=cvk)\n",
    "\n",
    "            df_list.append(pd.DataFrame({'score': scores_list, 'cvk':[cvk]*cvk, 'solver':[solver_name]*cvk}))\n",
    "\n",
    "            new_score_record = pd.DataFrame({'cvk': cvk, 'solver': solver_name, 'init_model': reg_model, \n",
    "                                             'mean_score': np.mean(scores_list)}, index=[idx])\n",
    "            reg_mean_scores_df = pd.concat([reg_mean_scores_df,new_score_record], axis=0)\n",
    "            idx += 1\n",
    "    reg_results = pd.concat(df_list)\n",
    "    \n",
    "    return reg_mean_scores_df, reg_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15526cef",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c79e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/in-vehicle-coupon-recommendation.csv\"\n",
    "data = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8995a9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12684, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82562d87",
   "metadata": {},
   "source": [
    "## Check for imbalance\n",
    "Full dataset: 57% Yes  \n",
    "\n",
    "### Coupon type subsets\n",
    "\n",
    "Restaurant(<20) \t\t70.71% Yes\n",
    "Coffee House \t\t    49.92% Yes\n",
    "Carry out & Take away \t73.55% Yes\n",
    "Bar  \t\t            41.00% Yes\n",
    "Restaurant(20-50)  \t\t44.10% Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfeeab8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7210\n",
       "0    5474\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3349660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5684326710816777"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7210/12684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5760f4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant(<20) :\t\t70.71% Yes\n",
      "Coffee House :\t\t49.92% Yes\n",
      "Carry out & Take away :\t\t73.55% Yes\n",
      "Bar :\t\t41.00% Yes\n",
      "Restaurant(20-50) :\t\t44.10% Yes\n"
     ]
    }
   ],
   "source": [
    "for coupon_type in data.coupon.unique():\n",
    "    vc = data.loc[data['coupon'] == coupon_type, 'Y'].value_counts()\n",
    "    print(f'{coupon_type} :\\t\\t{100*vc[1]/(vc[0]+vc[1]):.2f}% Yes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7eacd",
   "metadata": {},
   "source": [
    "## How many records do we have for each coupon type?\n",
    "Note: Numbers are kind of small... especially for the expensive restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8363681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coffee House             3996\n",
       "Restaurant(<20)          2786\n",
       "Carry out & Take away    2393\n",
       "Bar                      2017\n",
       "Restaurant(20-50)        1492\n",
       "Name: coupon, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.coupon.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e0c0c",
   "metadata": {},
   "source": [
    "## Cleaning: Drop mostly null feature 'car'\n",
    "Only 108/12684 records include this feature, and it's not mentioned in the feature descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "307213a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scooter and motorcycle                      22\n",
       "Mazda5                                      22\n",
       "do not drive                                22\n",
       "crossover                                   21\n",
       "Car that is too old to install Onstar :D    21\n",
       "Name: car, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.car.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c08a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('car', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019bd6b5",
   "metadata": {},
   "source": [
    "## Extract Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9603cd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temperature', 'has_children', 'toCoupon_GEQ5min', 'toCoupon_GEQ15min',\n",
       "       'toCoupon_GEQ25min', 'direction_same', 'direction_opp', 'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data = data.select_dtypes('number')\n",
    "numeric_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226587d2",
   "metadata": {},
   "source": [
    "### Check for Null values \n",
    "Result: no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfef414e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_colnames = numeric_data.columns[numeric_data.isna().any()].tolist()\n",
    "nan_colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b1a16",
   "metadata": {},
   "source": [
    "## Define X,y train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6cae210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define X and y \n",
    "X = numeric_data.drop('Y', axis=1).reset_index(drop=True)\n",
    "y = numeric_data.Y\n",
    "\n",
    "## Data splitting train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6c4c1",
   "metadata": {},
   "source": [
    "# Evaluate using only numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd52d7",
   "metadata": {},
   "source": [
    "## logistic_regression_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "489fdfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvk</th>\n",
       "      <th>solver</th>\n",
       "      <th>init_model</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.58549350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.58549350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>LogisticRegression(solver='liblinear')</td>\n",
       "      <td>0.58460868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.58460868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cvk     solver                              init_model  mean_score\n",
       "0    5  liblinear  LogisticRegression(solver='liblinear')  0.58549350\n",
       "1    5      lbfgs                    LogisticRegression()  0.58549350\n",
       "2   10  liblinear  LogisticRegression(solver='liblinear')  0.58460868\n",
       "3   10      lbfgs                    LogisticRegression()  0.58460868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_mean_scores_df, reg_results = run_logistic_regression_trials(X_train, y_train)\n",
    "display(reg_mean_scores_df.sort_values('mean_score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22a504",
   "metadata": {},
   "source": [
    "## Single RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afabe2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5910123893203718 0.0063071195794977206\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, random_state=42)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(f\"{np.mean(cross_val_scores)} {np.std(cross_val_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3aa281",
   "metadata": {},
   "source": [
    "# Add Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21752b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['destination', 'passanger', 'weather', 'time', 'coupon', 'expiration',\n",
       "       'gender', 'age', 'maritalStatus', 'education', 'occupation', 'income',\n",
       "       'Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20',\n",
       "       'Restaurant20To50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data = data.select_dtypes('object')\n",
    "categorical_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d488bbb1",
   "metadata": {},
   "source": [
    "## Replace missing values with 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3289cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_colnames = categorical_data.columns[categorical_data.isna().any()].tolist()\n",
    "nan_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7465fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29897a",
   "metadata": {},
   "source": [
    "## Ordinal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "231847fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_colnames = ['income', 'time', 'education', \n",
    "                   'Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50']\n",
    "ordinal_data = categorical_data[ordinal_colnames]\n",
    "\n",
    "ordinal_categories_list = [['Less than $12500', '$12500 - $24999', '$25000 - $37499', '$37500 - $49999',\n",
    "                            '$50000 - $62499', '$62500 - $74999', '$75000 - $87499', '$87500 - $99999',\n",
    "                            '$100000 or More'],\n",
    "                           ['7AM', '10AM', '2PM', '6PM', '10PM'],\n",
    "                           ['Some High School', 'High School Graduate', 'Some college - no degree',\n",
    "                            'Associates degree', 'Bachelors degree', 'Graduate degree (Masters or Doctorate)'],\n",
    "                           ['unknown', 'never', 'less1', '1~3', '4~8', 'gt8'],\n",
    "                           ['unknown', 'never', 'less1', '1~3', '4~8', 'gt8'],\n",
    "                           ['unknown', 'never', 'less1', '1~3', '4~8', 'gt8'],\n",
    "                           ['unknown', 'never', 'less1', '1~3', '4~8', 'gt8'],\n",
    "                           ['unknown', 'never', 'less1', '1~3', '4~8', 'gt8']]\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=ordinal_categories_list)\n",
    "\n",
    "## run the encoding\n",
    "ordinal_encoded_data = pd.DataFrame(ordinal_encoder.fit_transform(ordinal_data), columns=ordinal_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5fa7c",
   "metadata": {},
   "source": [
    "## Nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdec8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_data = categorical_data.drop(ordinal_colnames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "533112f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['destination', 'passanger', 'weather', 'coupon', 'expiration', 'gender',\n",
       "       'age', 'maritalStatus', 'occupation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominal_data.columns\n",
    "nominal_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4a3a9",
   "metadata": {},
   "source": [
    "## Encode nominals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3044059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_nominal_data = pd.get_dummies(nominal_data, drop_first=True)\n",
    "encoded_nominal_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0edcb5",
   "metadata": {},
   "source": [
    "## All features: define X/y train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f713669",
   "metadata": {},
   "outputs": [],
   "source": [
    "recombined_data = pd.concat([numeric_data, ordinal_encoded_data, encoded_nominal_data], axis=1)\n",
    "\n",
    "## define X and y \n",
    "X = recombined_data.drop('Y', axis=1).reset_index(drop=True)\n",
    "y = recombined_data.Y\n",
    "\n",
    "## Data splitting train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd356e",
   "metadata": {},
   "source": [
    "## single random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7f7cadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6780327614127175 0.0075288597072811665\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, random_state=42)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(f\"{np.mean(cross_val_scores)} {np.std(cross_val_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4d829",
   "metadata": {},
   "source": [
    "# Split and analyse by coupon type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ae22ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_nominal_data_no_coupon = pd.get_dummies(nominal_data.drop('coupon', axis=1), drop_first=True)\n",
    "data_to_split = pd.concat([numeric_data, ordinal_encoded_data, encoded_nominal_data_no_coupon, \n",
    "                           nominal_data.coupon], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee9bc6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = data_to_split.columns.to_list()\n",
    "cols_to_keep.remove('coupon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8aa8f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bar_data = data_to_split.loc[data_to_split['coupon'] == 'Bar', cols_to_keep]\n",
    "CoffeeHouse_data = data_to_split.loc[data_to_split['coupon'] == 'Coffee House', cols_to_keep]\n",
    "CarryAway_data = data_to_split.loc[data_to_split['coupon'] == 'Carry out & Take away', cols_to_keep]\n",
    "RestaurantLessThan20_data = data_to_split.loc[data_to_split['coupon'] == 'Restaurant(<20)', cols_to_keep]\n",
    "Restaurant20To50_data = data_to_split.loc[data_to_split['coupon'] == 'Restaurant(20-50)', cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbcaa14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
